{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DSM on SUPPORT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The SUPPORT dataset comes from the Vanderbilt University study\n",
    "to estimate survival for seriously ill hospitalized adults.\n",
    "(Refer to http://biostat.mc.vanderbilt.edu/wiki/Main/SupportDesc.\n",
    "for the original datasource.)\n",
    "\n",
    "In this notebook, we will apply Deep Survival Machines for survival prediction on the SUPPORT data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the SUPPORT Dataset\n",
    "\n",
    "The package includes helper functions to load the dataset.\n",
    "\n",
    "X represents an np.array of features (covariates),\n",
    "T is the event/censoring times and,\n",
    "E is the censoring indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from auton_survival import datasets\n",
    "outcomes, features = datasets.load_support_modified()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from auton_survival.preprocessing import Preprocessor\n",
    "# cat_feats = ['sex', 'dzgroup', 'dzclass', 'income', 'race', 'ca']\n",
    "# num_feats = ['age', 'num.co', 'meanbp', 'wblc', 'hrt', 'resp',\n",
    "# \t     'temp', 'pafi', 'alb', 'bili', 'crea', 'sod', 'ph',\n",
    "#              'glucose', 'bun', 'urine', 'adlp', 'adls']\n",
    "\n",
    "num_feats = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "cat_feats = [\"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\",\n",
    "                    \"23\", \"24\", \"25\", \"26\"]\n",
    "\n",
    "features = Preprocessor().fit_transform(features, cat_feats=cat_feats, num_feats=num_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compute horizons at which we evaluate the performance of DSM\n",
    "\n",
    "Survival predictions are issued at certain time horizons. Here we will evaluate the performance\n",
    "of DSM to issue predictions at the 25th, 50th and 75th event time quantile as is standard practice in Survival Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "horizons = [0.25, 0.5, 0.75]\n",
    "times = np.quantile(outcomes.time[outcomes.event==1], horizons).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Splitting the data into train, test and validation sets\n",
    "\n",
    "We will train DSM on 70% of the Data, use a Validation set of 10% for Model Selection and report performance on the remaining 20% held out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x, t, e = features.values, outcomes.time.values, outcomes.event.values\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "tr_size = int(n*0.60)\n",
    "vl_size = int(n*0.20)\n",
    "te_size = int(n*0.20)\n",
    "\n",
    "x_train, x_test, x_val = x[:tr_size], x[-te_size:], x[tr_size:tr_size+vl_size]\n",
    "t_train, t_test, t_val = t[:tr_size], t[-te_size:], t[tr_size:tr_size+vl_size]\n",
    "e_train, e_test, e_val = e[:tr_size], e[-te_size:], e[tr_size:tr_size+vl_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setting the parameter grid\n",
    "\n",
    "Lets set up the parameter grid to tune hyper-parameters. We will tune the number of underlying survival distributions, \n",
    "($K$), the distribution choices (Log-Normal or Weibull), the learning rate for the Adam optimizer between $1\\times10^{-3}$ and $1\\times10^{-4}$ and the number of hidden layers between $0, 1$ and $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'k' : [3, 4, 6],\n",
    "              'distribution' : ['LogNormal', 'Weibull'],\n",
    "              'learning_rate' : [1e-3, 1e-3],\n",
    "              'layers' : [ [], [32], [32, 32], [32, 64], [64, 64]]\n",
    "             }\n",
    "params = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model Training and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from auton_survival.models.dsm import DeepSurvivalMachines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8327/10000 [00:11<00:02, 730.86it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.06it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 790.19it/s]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.71it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 782.30it/s]\n",
      " 65%|██████▌   | 13/20 [00:04<00:02,  2.72it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 794.17it/s]\n",
      " 65%|██████▌   | 13/20 [00:04<00:02,  2.70it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 788.57it/s]\n",
      " 40%|████      | 8/20 [00:03<00:04,  2.58it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 785.92it/s]\n",
      " 40%|████      | 8/20 [00:03<00:05,  2.37it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 769.91it/s]\n",
      " 40%|████      | 8/20 [00:03<00:04,  2.62it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 786.90it/s]\n",
      " 40%|████      | 8/20 [00:03<00:04,  2.53it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 787.65it/s]\n",
      " 35%|███▌      | 7/20 [00:04<00:07,  1.68it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 792.82it/s]\n",
      " 35%|███▌      | 7/20 [00:04<00:07,  1.67it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 774.33it/s]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.55it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 795.09it/s]\n",
      "100%|██████████| 20/20 [00:05<00:00,  3.53it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 786.19it/s]\n",
      " 65%|██████▌   | 13/20 [00:04<00:02,  2.74it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 779.00it/s]\n",
      " 65%|██████▌   | 13/20 [00:04<00:02,  2.65it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 778.98it/s]\n",
      " 40%|████      | 8/20 [00:03<00:05,  2.35it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 788.48it/s]\n",
      " 40%|████      | 8/20 [00:03<00:04,  2.42it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 757.22it/s]\n",
      " 40%|████      | 8/20 [00:03<00:05,  2.16it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 782.82it/s]\n",
      " 40%|████      | 8/20 [00:03<00:04,  2.41it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 782.27it/s]\n",
      " 50%|█████     | 10/20 [00:05<00:05,  1.75it/s]\n",
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 761.57it/s]\n",
      " 50%|█████     | 10/20 [00:06<00:06,  1.63it/s]\n",
      " 21%|██        | 2119/10000 [00:02<00:10, 726.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m     model \u001B[38;5;241m=\u001B[39m DeepSurvivalMachines(k \u001B[38;5;241m=\u001B[39m param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      4\u001B[0m                                  distribution \u001B[38;5;241m=\u001B[39m param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistribution\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      5\u001B[0m                                  layers \u001B[38;5;241m=\u001B[39m param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlayers\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# The fit method is called to train the model\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miters\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mparam\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlearning_rate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     models\u001B[38;5;241m.\u001B[39mappend([[model\u001B[38;5;241m.\u001B[39mcompute_nll(x_val, t_val, e_val), model]])\n\u001B[1;32m      9\u001B[0m best_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(models)\n",
      "File \u001B[0;32m~/Documents/GitHub/DeepSurvivalMachines/auton_survival/models/dsm/__init__.py:260\u001B[0m, in \u001B[0;36mDSMBase.fit\u001B[0;34m(self, x, t, e, vsize, val_data, iters, learning_rate, batch_size, elbo, optimizer)\u001B[0m\n\u001B[1;32m    258\u001B[0m maxrisk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mnanmax(e_train\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()))\n\u001B[1;32m    259\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gen_torch_model(inputdim, optimizer, risks\u001B[38;5;241m=\u001B[39mmaxrisk)\n\u001B[0;32m--> 260\u001B[0m model, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dsm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m                     \u001B[49m\u001B[43melbo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43melbo\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mbs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtorch_model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfitted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/GitHub/DeepSurvivalMachines/auton_survival/models/dsm/utilities.py:132\u001B[0m, in \u001B[0;36mtrain_dsm\u001B[0;34m(model, x_train, t_train, e_train, x_valid, t_valid, e_valid, n_iter, lr, elbo, bs, random_seed)\u001B[0m\n\u001B[1;32m    129\u001B[0m t_valid_ \u001B[38;5;241m=\u001B[39m _reshape_tensor_with_nans(t_valid)\n\u001B[1;32m    130\u001B[0m e_valid_ \u001B[38;5;241m=\u001B[39m _reshape_tensor_with_nans(e_valid)\n\u001B[0;32m--> 132\u001B[0m premodel \u001B[38;5;241m=\u001B[39m \u001B[43mpretrain_dsm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mt_train_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    134\u001B[0m \u001B[43m                        \u001B[49m\u001B[43me_train_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mt_valid_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[43m                        \u001B[49m\u001B[43me_valid_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mthres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(model\u001B[38;5;241m.\u001B[39mrisks):\n\u001B[1;32m    142\u001B[0m   model\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;28mstr\u001B[39m(r\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)]\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill_(\u001B[38;5;28mfloat\u001B[39m(premodel\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;28mstr\u001B[39m(r\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)]))\n",
      "File \u001B[0;32m~/Documents/GitHub/DeepSurvivalMachines/auton_survival/models/dsm/utilities.py:73\u001B[0m, in \u001B[0;36mpretrain_dsm\u001B[0;34m(model, t_train, e_train, t_valid, e_valid, n_iter, lr, thres)\u001B[0m\n\u001B[1;32m     71\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(model\u001B[38;5;241m.\u001B[39mrisks):\n\u001B[0;32m---> 73\u001B[0m   loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43munconditional_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpremodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     74\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     75\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Documents/GitHub/DeepSurvivalMachines/auton_survival/models/dsm/losses.py:123\u001B[0m, in \u001B[0;36munconditional_loss\u001B[0;34m(model, t, e, risk)\u001B[0m\n\u001B[1;32m    121\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _weibull_loss(model, t, e, risk)\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mdist \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLogNormal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 123\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_lognormal_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrisk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m model\u001B[38;5;241m.\u001B[39mdist \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNormal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    125\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _normal_loss(model, t, e, risk)\n",
      "File \u001B[0;32m~/Documents/GitHub/DeepSurvivalMachines/auton_survival/models/dsm/losses.py:82\u001B[0m, in \u001B[0;36m_lognormal_loss\u001B[0;34m(model, t, e, risk)\u001B[0m\n\u001B[1;32m     79\u001B[0m sigma \u001B[38;5;241m=\u001B[39m b_[:, g]\n\u001B[1;32m     81\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m sigma \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39mpi)\n\u001B[0;32m---> 82\u001B[0m f \u001B[38;5;241m=\u001B[39m f \u001B[38;5;241m-\u001B[39m torch\u001B[38;5;241m.\u001B[39mdiv((torch\u001B[38;5;241m.\u001B[39mlog(t) \u001B[38;5;241m-\u001B[39m mu)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2.\u001B[39m\u001B[38;5;241m*\u001B[39mtorch\u001B[38;5;241m.\u001B[39mexp(\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msigma\u001B[49m))\n\u001B[1;32m     83\u001B[0m s \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdiv(torch\u001B[38;5;241m.\u001B[39mlog(t) \u001B[38;5;241m-\u001B[39m mu, torch\u001B[38;5;241m.\u001B[39mexp(sigma)\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m     84\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39mtorch\u001B[38;5;241m.\u001B[39merf(s)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for param in params:\n",
    "    model = DeepSurvivalMachines(k = param['k'],\n",
    "                                 distribution = param['distribution'],\n",
    "                                 layers = param['layers'])\n",
    "    # The fit method is called to train the model\n",
    "    model.fit(x_train, t_train, e_train, iters = 20, learning_rate = param['learning_rate'])\n",
    "    models.append([[model.compute_nll(x_val, t_val, e_val), model]])\n",
    "best_model = min(models)\n",
    "model = best_model[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8327/10000 [00:11<00:02, 743.75it/s]\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.9532095255164017"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8327/10000 [00:10<00:02, 782.04it/s]\n",
      "100%|██████████| 20/20 [00:09<00:00,  2.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.9532095255164017"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepSurvivalMachines(k = 1,\n",
    "                             distribution = 'LogNormal',\n",
    "                             layers = [64, 64, 64])\n",
    "# The fit method is called to train the model\n",
    "model.fit(x_train, t_train, e_train, iters = 20, learning_rate = 1e-3)\n",
    "model.compute_nll(x_val, t_val, e_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out_risk = model.predict_risk(x_test, times)\n",
    "out_survival = model.predict_survival(x_test, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "We evaluate the performance of DSM in its discriminative ability (Time Dependent Concordance Index and Cumulative Dynamic AUC) as well as Brier Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_ipcw, brier_score, cumulative_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 0.25 quantile,\n",
      "TD Concordance Index: 0.7705086576570083\n",
      "Brier Score: 0.12668397740160176\n",
      "ROC AUC  0.7818957741333745 \n",
      "\n",
      "For 0.5 quantile,\n",
      "TD Concordance Index: 0.7109732295815918\n",
      "Brier Score: 0.21588082086909596\n",
      "ROC AUC  0.7074795006013634 \n",
      "\n",
      "For 0.75 quantile,\n",
      "TD Concordance Index: 0.5479697899450495\n",
      "Brier Score: 0.2074402978136717\n",
      "ROC AUC  0.7749528448371327 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cis = []\n",
    "brs = []\n",
    "\n",
    "et_train = np.array([(e_train[i], t_train[i]) for i in range(len(e_train))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "et_test = np.array([(e_test[i], t_test[i]) for i in range(len(e_test))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "et_val = np.array([(e_val[i], t_val[i]) for i in range(len(e_val))],\n",
    "                 dtype = [('e', bool), ('t', float)])\n",
    "\n",
    "for i, _ in enumerate(times):\n",
    "    cis.append(concordance_index_ipcw(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "brs.append(brier_score(et_train, et_test, out_survival, times)[1])\n",
    "roc_auc = []\n",
    "for i, _ in enumerate(times):\n",
    "    roc_auc.append(cumulative_dynamic_auc(et_train, et_test, out_risk[:, i], times[i])[0])\n",
    "for horizon in enumerate(horizons):\n",
    "    print(f\"For {horizon[1]} quantile,\")\n",
    "    print(\"TD Concordance Index:\", cis[horizon[0]])\n",
    "    print(\"Brier Score:\", brs[0][horizon[0]])\n",
    "    print(\"ROC AUC \", roc_auc[horizon[0]][0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}