{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.covariate_data_processing import pbc2_proccess_covariate, padded_mask_processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/davidlee/Documents/GitHub/Surtimesurvival/Data Project/Pycox Lib/PBC2 Convariate Data/pbc2_data_proccessed_auton_covariate.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   event       time  seq_id  seq_time_id  seq_temporal_SGOT  seq_temporal_age  \\\n0    1.0   0.569489       0     0.569489          -1.485263          0.248058   \n1    1.0   0.569489       0     1.095170           0.195488          0.248058   \n2    0.0  14.152338       1     5.319790          -0.442126          1.292856   \n3    0.0  14.152338       1     6.261636          -0.046806          1.292856   \n4    0.0  14.152338       1     7.266455           0.293680          1.292856   \n\n   seq_temporal_albumin  seq_temporal_alkaline  seq_temporal_platelets  \\\n0             -0.894575               0.195532               -0.529101   \n1             -1.570646               0.285613               -0.456022   \n2             -1.431455              -0.605844               -1.395605   \n3             -1.172958              -0.512364               -1.259888   \n4             -1.312149              -0.443529               -1.364286   \n\n   seq_temporal_prothrombin  ...  seq_temporal_drug_1.0  \\\n0                  0.136768  ...                      0   \n1                  0.813132  ...                      0   \n2                  0.339677  ...                      0   \n3                  0.339677  ...                      0   \n4                  0.339677  ...                      0   \n\n   seq_temporal_edema_1.0  seq_temporal_edema_2.0  \\\n0                       1                       0   \n1                       1                       0   \n2                       1                       0   \n3                       1                       0   \n4                       1                       0   \n\n   seq_temporal_hepatomegaly_1.0  seq_temporal_hepatomegaly_2.0  \\\n0                              1                              0   \n1                              1                              0   \n2                              1                              0   \n3                              1                              0   \n4                              1                              0   \n\n   seq_temporal_histologic_1.0  seq_temporal_histologic_2.0  \\\n0                            0                            0   \n1                            0                            0   \n2                            0                            1   \n3                            0                            1   \n4                            0                            1   \n\n   seq_temporal_histologic_3.0  seq_temporal_spiders_1.0  \\\n0                            1                         1   \n1                            1                         1   \n2                            0                         1   \n3                            0                         1   \n4                            0                         1   \n\n   seq_temporal_spiders_2.0  \n0                         0  \n1                         0  \n2                         0  \n3                         0  \n4                         0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event</th>\n      <th>time</th>\n      <th>seq_id</th>\n      <th>seq_time_id</th>\n      <th>seq_temporal_SGOT</th>\n      <th>seq_temporal_age</th>\n      <th>seq_temporal_albumin</th>\n      <th>seq_temporal_alkaline</th>\n      <th>seq_temporal_platelets</th>\n      <th>seq_temporal_prothrombin</th>\n      <th>...</th>\n      <th>seq_temporal_drug_1.0</th>\n      <th>seq_temporal_edema_1.0</th>\n      <th>seq_temporal_edema_2.0</th>\n      <th>seq_temporal_hepatomegaly_1.0</th>\n      <th>seq_temporal_hepatomegaly_2.0</th>\n      <th>seq_temporal_histologic_1.0</th>\n      <th>seq_temporal_histologic_2.0</th>\n      <th>seq_temporal_histologic_3.0</th>\n      <th>seq_temporal_spiders_1.0</th>\n      <th>seq_temporal_spiders_2.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.569489</td>\n      <td>0</td>\n      <td>0.569489</td>\n      <td>-1.485263</td>\n      <td>0.248058</td>\n      <td>-0.894575</td>\n      <td>0.195532</td>\n      <td>-0.529101</td>\n      <td>0.136768</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.569489</td>\n      <td>0</td>\n      <td>1.095170</td>\n      <td>0.195488</td>\n      <td>0.248058</td>\n      <td>-1.570646</td>\n      <td>0.285613</td>\n      <td>-0.456022</td>\n      <td>0.813132</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>14.152338</td>\n      <td>1</td>\n      <td>5.319790</td>\n      <td>-0.442126</td>\n      <td>1.292856</td>\n      <td>-1.431455</td>\n      <td>-0.605844</td>\n      <td>-1.395605</td>\n      <td>0.339677</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>14.152338</td>\n      <td>1</td>\n      <td>6.261636</td>\n      <td>-0.046806</td>\n      <td>1.292856</td>\n      <td>-1.172958</td>\n      <td>-0.512364</td>\n      <td>-1.259888</td>\n      <td>0.339677</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>14.152338</td>\n      <td>1</td>\n      <td>7.266455</td>\n      <td>0.293680</td>\n      <td>1.292856</td>\n      <td>-1.312149</td>\n      <td>-0.443529</td>\n      <td>-1.364286</td>\n      <td>0.339677</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_temp = df.loc[0:, ['seq_id', 'seq_time_id', 'event', 'time']]\n",
    "df = df.drop(columns=['seq_id', 'seq_time_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   event       time  seq_temporal_SGOT  seq_temporal_age  \\\n0    1.0   0.569489          -1.485263          0.248058   \n1    1.0   0.569489           0.195488          0.248058   \n2    0.0  14.152338          -0.442126          1.292856   \n3    0.0  14.152338          -0.046806          1.292856   \n4    0.0  14.152338           0.293680          1.292856   \n\n   seq_temporal_albumin  seq_temporal_alkaline  seq_temporal_platelets  \\\n0             -0.894575               0.195532               -0.529101   \n1             -1.570646               0.285613               -0.456022   \n2             -1.431455              -0.605844               -1.395605   \n3             -1.172958              -0.512364               -1.259888   \n4             -1.312149              -0.443529               -1.364286   \n\n   seq_temporal_prothrombin  seq_temporal_serBilir  seq_temporal_serChol  ...  \\\n0                  0.136768               3.281890          1.169016e-16  ...   \n1                  0.813132               2.015877         -4.694608e-01  ...   \n2                  0.339677               0.172710         -6.589138e-01  ...   \n3                  0.339677              -0.013468         -6.036567e-01  ...   \n4                  0.339677               0.098239          1.169016e-16  ...   \n\n   seq_temporal_drug_1.0  seq_temporal_edema_1.0  seq_temporal_edema_2.0  \\\n0                      0                       1                       0   \n1                      0                       1                       0   \n2                      0                       1                       0   \n3                      0                       1                       0   \n4                      0                       1                       0   \n\n   seq_temporal_hepatomegaly_1.0  seq_temporal_hepatomegaly_2.0  \\\n0                              1                              0   \n1                              1                              0   \n2                              1                              0   \n3                              1                              0   \n4                              1                              0   \n\n   seq_temporal_histologic_1.0  seq_temporal_histologic_2.0  \\\n0                            0                            0   \n1                            0                            0   \n2                            0                            1   \n3                            0                            1   \n4                            0                            1   \n\n   seq_temporal_histologic_3.0  seq_temporal_spiders_1.0  \\\n0                            1                         1   \n1                            1                         1   \n2                            0                         1   \n3                            0                         1   \n4                            0                         1   \n\n   seq_temporal_spiders_2.0  \n0                         0  \n1                         0  \n2                         0  \n3                         0  \n4                         0  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>event</th>\n      <th>time</th>\n      <th>seq_temporal_SGOT</th>\n      <th>seq_temporal_age</th>\n      <th>seq_temporal_albumin</th>\n      <th>seq_temporal_alkaline</th>\n      <th>seq_temporal_platelets</th>\n      <th>seq_temporal_prothrombin</th>\n      <th>seq_temporal_serBilir</th>\n      <th>seq_temporal_serChol</th>\n      <th>...</th>\n      <th>seq_temporal_drug_1.0</th>\n      <th>seq_temporal_edema_1.0</th>\n      <th>seq_temporal_edema_2.0</th>\n      <th>seq_temporal_hepatomegaly_1.0</th>\n      <th>seq_temporal_hepatomegaly_2.0</th>\n      <th>seq_temporal_histologic_1.0</th>\n      <th>seq_temporal_histologic_2.0</th>\n      <th>seq_temporal_histologic_3.0</th>\n      <th>seq_temporal_spiders_1.0</th>\n      <th>seq_temporal_spiders_2.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.569489</td>\n      <td>-1.485263</td>\n      <td>0.248058</td>\n      <td>-0.894575</td>\n      <td>0.195532</td>\n      <td>-0.529101</td>\n      <td>0.136768</td>\n      <td>3.281890</td>\n      <td>1.169016e-16</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.569489</td>\n      <td>0.195488</td>\n      <td>0.248058</td>\n      <td>-1.570646</td>\n      <td>0.285613</td>\n      <td>-0.456022</td>\n      <td>0.813132</td>\n      <td>2.015877</td>\n      <td>-4.694608e-01</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>14.152338</td>\n      <td>-0.442126</td>\n      <td>1.292856</td>\n      <td>-1.431455</td>\n      <td>-0.605844</td>\n      <td>-1.395605</td>\n      <td>0.339677</td>\n      <td>0.172710</td>\n      <td>-6.589138e-01</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>14.152338</td>\n      <td>-0.046806</td>\n      <td>1.292856</td>\n      <td>-1.172958</td>\n      <td>-0.512364</td>\n      <td>-1.259888</td>\n      <td>0.339677</td>\n      <td>-0.013468</td>\n      <td>-6.036567e-01</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>14.152338</td>\n      <td>0.293680</td>\n      <td>1.292856</td>\n      <td>-1.312149</td>\n      <td>-0.443529</td>\n      <td>-1.364286</td>\n      <td>0.339677</td>\n      <td>0.098239</td>\n      <td>1.169016e-16</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df.rename(columns={'time': 'duration'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n",
      "______\n",
      "8\n",
      "______\n",
      "13\n",
      "______\n",
      "21\n",
      "______\n",
      "26\n",
      "______\n",
      "[2.73792575e-03 3.83309605e-02 1.86178951e-01 4.73661154e-01\n",
      " 1.43056620e+01]\n",
      "______\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/Documents/GitHub/Surtimesurvival/SurvTRACE/survtrace/utils.py:78: UserWarning: Got event/censoring at start time. Should be removed! It is set s.t. it has no contribution to loss.\n",
      "  warnings.warn(\"\"\"Got event/censoring at start time. Should be removed! It is set s.t. it has no contribution to loss.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "y, df, df_train, df_y_train = pbc2_proccess_covariate(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_temp['seq_id']], axis=1, join='inner')\n",
    "df_y_train = pd.concat([df_y_train, df_temp['seq_id']], axis=1, join='inner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    }
   ],
   "source": [
    "masks, padded_patients = padded_mask_processing(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([312, 16, 21])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_patients.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([312, 16])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_y_train = df_y_train.drop_duplicates(subset='seq_id', keep='last')\n",
    "df_y_train = df_y_train.reset_index(drop=True)\n",
    "df_y_train = df_y_train.drop(columns=['seq_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   duration  event  proportion\n0         3    1.0    0.006928\n1         3    0.0    0.988915\n2         3    1.0    0.019002\n3         2    1.0    0.314286\n4         3    0.0    0.263658",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration</th>\n      <th>event</th>\n      <th>proportion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0.006928</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.988915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0.019002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.314286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.263658</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop_duplicates(subset='seq_id', keep='last')\n",
    "df_temp = df_temp.reset_index(drop=True)\n",
    "df_temp = df_temp.drop(columns=['seq_id'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   seq_time_id  event       time\n0     1.095170    1.0   0.569489\n1    14.152338    0.0  14.152338\n2     2.770781    1.0   0.736502\n3     5.270507    1.0   0.276531\n4     4.120578    0.0   4.120578",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_time_id</th>\n      <th>event</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.095170</td>\n      <td>1.0</td>\n      <td>0.569489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14.152338</td>\n      <td>0.0</td>\n      <td>14.152338</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.770781</td>\n      <td>1.0</td>\n      <td>0.736502</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.270507</td>\n      <td>1.0</td>\n      <td>0.276531</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.120578</td>\n      <td>0.0</td>\n      <td>4.120578</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X_features_data_tensor = padded_patients\n",
    "Y_labels_data_tensor = torch.tensor(df_y_train.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "Y_labels = Y_labels_data_tensor[:, 1]\n",
    "Y_labels = Y_labels.long()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n        1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n        1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n        0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "X_train, X_val, y_train, y_val, masks_train, masks_val = train_test_split(X_features_data_tensor, Y_labels, masks,\n",
    "                                                                          test_size=0.3)\n",
    "train_data = TensorDataset(X_train, y_train, masks_train)\n",
    "val_data = TensorDataset(X_val, y_val, masks_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimension 21\n",
      "Sequence Length 16\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from model.survtimesurvival_model import TransformerClassifierFirstSolution, TransformerClassifier\n",
    "\n",
    "# Hyperparameters\n",
    "# input_dim = 26\n",
    "embed_dim = 16\n",
    "num_heads = 2\n",
    "ffn_hidden_dim = 64\n",
    "num_layers = 2\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set up training configurations\n",
    "input_dim = X_features_data_tensor.size(2)\n",
    "seq_length = X_features_data_tensor.size(1)\n",
    "\n",
    "print(\"Input Dimension\", input_dim)\n",
    "print(\"Sequence Length\", seq_length)\n",
    "\n",
    "model = TransformerClassifierFirstSolution(input_dim, seq_length, embed_dim, num_heads, ffn_hidden_dim, num_layers, 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# HUNG: IMPORTANCE. IF YOU KEEP nn.CrossEntropyLoss(), this loss will return a number!!!!\n",
    "# criterion = nn.NLLLoss(reduction=\"none\")\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Training Loss: 1.0723985135555267, Validation Loss: 5.011917074521382, Validation Accuracy: 0.7659574468085106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40, Training Loss: 0.9867225182907922, Validation Loss: 4.427886585394542, Validation Accuracy: 0.7659574468085106\n",
      "Epoch 3/40, Training Loss: 0.9265503287315369, Validation Loss: 4.214466551939647, Validation Accuracy: 0.7978723404255319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40, Training Loss: 0.926602983048984, Validation Loss: 4.243187228838603, Validation Accuracy: 0.7978723404255319\n",
      "Epoch 5/40, Training Loss: 0.8854745956403869, Validation Loss: 4.113593876361847, Validation Accuracy: 0.8085106382978723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40, Training Loss: 0.8996716716459819, Validation Loss: 4.060795724391937, Validation Accuracy: 0.8191489361702128\n",
      "Epoch 7/40, Training Loss: 0.8334443036999021, Validation Loss: 4.070714871088664, Validation Accuracy: 0.8085106382978723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40, Training Loss: 0.8002360186406544, Validation Loss: 4.003569444020589, Validation Accuracy: 0.8191489361702128\n",
      "Epoch 9/40, Training Loss: 0.8162669645888465, Validation Loss: 3.8894928296407065, Validation Accuracy: 0.8191489361702128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40, Training Loss: 0.8242608713252204, Validation Loss: 3.950289229551951, Validation Accuracy: 0.8085106382978723\n",
      "Epoch 11/40, Training Loss: 0.8376639591796058, Validation Loss: 4.031917174657186, Validation Accuracy: 0.7978723404255319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40, Training Loss: 0.8165727396096502, Validation Loss: 3.989801605542501, Validation Accuracy: 0.7872340425531915\n",
      "Epoch 13/40, Training Loss: 0.7942561741386142, Validation Loss: 4.210454722245534, Validation Accuracy: 0.7553191489361702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40, Training Loss: 0.8433605773108346, Validation Loss: 3.7938212354977927, Validation Accuracy: 0.8191489361702128\n",
      "Epoch 15/40, Training Loss: 0.803877558026995, Validation Loss: 4.049972434838613, Validation Accuracy: 0.776595744680851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40, Training Loss: 0.7819801419973373, Validation Loss: 3.8967848221460977, Validation Accuracy: 0.8191489361702128\n",
      "Epoch 17/40, Training Loss: 0.7817031805004392, Validation Loss: 3.904375374317169, Validation Accuracy: 0.7978723404255319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40, Training Loss: 0.7766721355063575, Validation Loss: 3.8403437733650208, Validation Accuracy: 0.8404255319148937\n",
      "Epoch 19/40, Training Loss: 0.7591853673968997, Validation Loss: 3.925266961256663, Validation Accuracy: 0.8085106382978723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40, Training Loss: 0.7430884529437337, Validation Loss: 3.7864442467689514, Validation Accuracy: 0.8297872340425532\n",
      "Epoch 21/40, Training Loss: 0.7705350475651878, Validation Loss: 3.8287646174430847, Validation Accuracy: 0.8191489361702128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40, Training Loss: 0.7975462302565575, Validation Loss: 4.81299755970637, Validation Accuracy: 0.6595744680851063\n",
      "Epoch 23/40, Training Loss: 0.7608835569449833, Validation Loss: 3.6383987069129944, Validation Accuracy: 0.851063829787234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40, Training Loss: 0.7537359041827065, Validation Loss: 4.213339984416962, Validation Accuracy: 0.7659574468085106\n",
      "Epoch 25/40, Training Loss: 0.816070590700422, Validation Loss: 3.5961402654647827, Validation Accuracy: 0.8617021276595744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40, Training Loss: 0.797865266246455, Validation Loss: 3.851067860921224, Validation Accuracy: 0.8191489361702128\n",
      "Epoch 27/40, Training Loss: 0.7997961906450135, Validation Loss: 3.6109567483266196, Validation Accuracy: 0.8404255319148937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40, Training Loss: 0.8456373108284814, Validation Loss: 4.083183467388153, Validation Accuracy: 0.7872340425531915\n",
      "Epoch 29/40, Training Loss: 0.7646866951669965, Validation Loss: 4.354299922784169, Validation Accuracy: 0.7340425531914894\n",
      "Epoch 30/40, Training Loss: 0.745347875569548, Validation Loss: 3.8057279189427695, Validation Accuracy: 0.8191489361702128\n",
      "Epoch 31/40, Training Loss: 0.7496420581425939, Validation Loss: 3.6810304323832193, Validation Accuracy: 0.8404255319148937\n",
      "Early stopping triggered. No improvement in validation loss for 5 consecutive epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "/Users/davidlee/opt/anaconda3/envs/synthcity/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/transformers/attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 40\n",
    "train_loss_his = []\n",
    "val_loss_his = []\n",
    "val_accuracy_his = []\n",
    "\n",
    "patience = 5\n",
    "best_val_loss = None\n",
    "epochs_since_best_val_loss = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target, label_mask) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, label_mask)\n",
    "        loss = criterion(output, target)\n",
    "        # Assume loss has shape (B, S, D). Assume mask has shape (B, S)\n",
    "        # Apply label mask to the loss.\n",
    "        # In the label. Assume 1 is NOT PAD, and 0 is pad.\n",
    "        loss = (loss * label_mask.unsqueeze(-1).float())\n",
    "\n",
    "        # Average over the third dimension\n",
    "        loss = loss.mean(-1)\n",
    "\n",
    "        # Average over each sequence (dimension 1).\n",
    "        # Since each sequence has different length. We need to do this\n",
    "        loss = torch.sum(loss, dim=-1) / torch.sum(label_mask, dim=-1, keepdim=True)\n",
    "\n",
    "        # Then average over the batch\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target, masks) in enumerate(val_loader):\n",
    "            output = model(data, masks)\n",
    "            loss = criterion(output, target)\n",
    "            # val_running_loss += loss.item()\n",
    "            val_running_loss += loss.sum().item()\n",
    "            # val_running_loss += loss.mean().item()\n",
    "            preds = output.argmax(dim=1).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    # Calculate the accuracy of the model on the validation set\n",
    "    val_accuracy = accuracy_score(val_targets, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "          f\"Training Loss: {running_loss / len(train_loader)}, \"\n",
    "          f\"Validation Loss: {val_running_loss / len(val_loader)}, \"\n",
    "          f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    train_loss_his.append(running_loss / len(train_loader))\n",
    "    val_loss_his.append(val_running_loss / len(val_loader))\n",
    "    val_accuracy_his.append(val_accuracy)\n",
    "    if best_val_loss is None or abs(val_running_loss) < abs(best_val_loss):\n",
    "        best_val_loss = val_running_loss\n",
    "        epochs_since_best_val_loss = 0\n",
    "    else:\n",
    "        epochs_since_best_val_loss += 1\n",
    "\n",
    "    if epochs_since_best_val_loss > patience:\n",
    "        print(f\"Early stopping triggered. No improvement in validation loss for {patience} consecutive epochs.\")\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'pre_trained_timevisit.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from model.survtimesurvival_model import TransformerClassifier_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerClassifier_2(input_dim, seq_length, embed_dim, num_heads, ffn_hidden_dim, num_layers, num_classes)\n",
    "pretrained_weights = torch.load('pretrained_weight/pre_trained_timevisit.pth')\n",
    "model.load_state_dict(pretrained_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    }
   ],
   "source": [
    "masks, padded_patients = padded_mask_processing(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "new_embedding = []\n",
    "for i in range(len(masks)):\n",
    "    a = masks[i].unsqueeze(0)\n",
    "    output = model(X_features_data_tensor[i], a)\n",
    "    new_embedding.append(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Convert each tensor to a numpy array and stack them\n",
    "numpy_arrays = [tensor.detach().numpy() for tensor in new_embedding]\n",
    "numpy_array = np.stack(numpy_arrays, axis=-1) # this stacks along a new third dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(numpy_array[0])\n",
    "new_df = new_df.transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "dataframe_for_survtrace = pd.concat([new_df, df_y_train],axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2         3         4         5         6  \\\n0 -0.446987  1.849092  0.305368  0.931363 -2.239734 -0.338914 -2.367347   \n1 -0.672468  0.648800 -0.001764  0.503774 -0.867893  0.321905 -1.178480   \n2 -0.505319  1.637821  0.275738  0.858761 -2.032792 -0.218516 -2.214883   \n3 -0.507373  1.688821  0.228196  0.972952 -2.094252 -0.200226 -2.419747   \n4 -0.459481  1.763930  0.316549  0.938090 -2.197446 -0.269603 -2.402856   \n\n          7         8         9  ...        14        15        16        17  \\\n0 -1.310586 -1.781363  0.549300  ... -2.386981 -0.560916  1.294427 -0.953799   \n1 -0.432639 -0.447578 -0.054342  ... -0.759589 -1.005411  0.904593 -0.432616   \n2 -1.176234 -1.521159  0.429962  ... -2.156593 -0.680408  1.268441 -0.898300   \n3 -1.236168 -1.678527  0.536669  ... -2.294627 -0.697956  1.399108 -0.841116   \n4 -1.303780 -1.729299  0.551554  ... -2.365541 -0.679100  1.351720 -0.910573   \n\n         18        19        20  duration  event  proportion  \n0  0.869661  0.632084 -1.690865         3    1.0    0.006928  \n1  0.087568  0.232107 -1.048942         3    0.0    0.988915  \n2  0.740181  0.557203 -1.637736         3    1.0    0.019002  \n3  0.843930  0.487410 -1.726512         2    1.0    0.314286  \n4  0.854094  0.538138 -1.766614         3    0.0    0.263658  \n\n[5 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>duration</th>\n      <th>event</th>\n      <th>proportion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.446987</td>\n      <td>1.849092</td>\n      <td>0.305368</td>\n      <td>0.931363</td>\n      <td>-2.239734</td>\n      <td>-0.338914</td>\n      <td>-2.367347</td>\n      <td>-1.310586</td>\n      <td>-1.781363</td>\n      <td>0.549300</td>\n      <td>...</td>\n      <td>-2.386981</td>\n      <td>-0.560916</td>\n      <td>1.294427</td>\n      <td>-0.953799</td>\n      <td>0.869661</td>\n      <td>0.632084</td>\n      <td>-1.690865</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0.006928</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.672468</td>\n      <td>0.648800</td>\n      <td>-0.001764</td>\n      <td>0.503774</td>\n      <td>-0.867893</td>\n      <td>0.321905</td>\n      <td>-1.178480</td>\n      <td>-0.432639</td>\n      <td>-0.447578</td>\n      <td>-0.054342</td>\n      <td>...</td>\n      <td>-0.759589</td>\n      <td>-1.005411</td>\n      <td>0.904593</td>\n      <td>-0.432616</td>\n      <td>0.087568</td>\n      <td>0.232107</td>\n      <td>-1.048942</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.988915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.505319</td>\n      <td>1.637821</td>\n      <td>0.275738</td>\n      <td>0.858761</td>\n      <td>-2.032792</td>\n      <td>-0.218516</td>\n      <td>-2.214883</td>\n      <td>-1.176234</td>\n      <td>-1.521159</td>\n      <td>0.429962</td>\n      <td>...</td>\n      <td>-2.156593</td>\n      <td>-0.680408</td>\n      <td>1.268441</td>\n      <td>-0.898300</td>\n      <td>0.740181</td>\n      <td>0.557203</td>\n      <td>-1.637736</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>0.019002</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.507373</td>\n      <td>1.688821</td>\n      <td>0.228196</td>\n      <td>0.972952</td>\n      <td>-2.094252</td>\n      <td>-0.200226</td>\n      <td>-2.419747</td>\n      <td>-1.236168</td>\n      <td>-1.678527</td>\n      <td>0.536669</td>\n      <td>...</td>\n      <td>-2.294627</td>\n      <td>-0.697956</td>\n      <td>1.399108</td>\n      <td>-0.841116</td>\n      <td>0.843930</td>\n      <td>0.487410</td>\n      <td>-1.726512</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.314286</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.459481</td>\n      <td>1.763930</td>\n      <td>0.316549</td>\n      <td>0.938090</td>\n      <td>-2.197446</td>\n      <td>-0.269603</td>\n      <td>-2.402856</td>\n      <td>-1.303780</td>\n      <td>-1.729299</td>\n      <td>0.551554</td>\n      <td>...</td>\n      <td>-2.365541</td>\n      <td>-0.679100</td>\n      <td>1.351720</td>\n      <td>-0.910573</td>\n      <td>0.854094</td>\n      <td>0.538138</td>\n      <td>-1.766614</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.263658</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_for_survtrace.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "   seq_time_id  event       time\n0     1.095170    1.0   0.569489\n1    14.152338    0.0  14.152338\n2     2.770781    1.0   0.736502\n3     5.270507    1.0   0.276531\n4     4.120578    0.0   4.120578",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_time_id</th>\n      <th>event</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.095170</td>\n      <td>1.0</td>\n      <td>0.569489</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14.152338</td>\n      <td>0.0</td>\n      <td>14.152338</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.770781</td>\n      <td>1.0</td>\n      <td>0.736502</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.270507</td>\n      <td>1.0</td>\n      <td>0.276531</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.120578</td>\n      <td>0.0</td>\n      <td>4.120578</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "dataframe_for_survtrace = pd.concat([dataframe_for_survtrace, df_temp['seq_time_id']], axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "dataframe_for_survtrace.rename(columns = {'proportion':'proportion_1'}, inplace = True)\n",
    "dataframe_for_survtrace.columns = dataframe_for_survtrace.columns.astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df_2 = dataframe_for_survtrace.drop(columns=['duration', 'proportion_1'])\n",
    "df_2.rename(columns = {'seq_time_id':'duration'}, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 312 entries, 0 to 311\n",
      "Data columns (total 23 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   0         312 non-null    float32\n",
      " 1   1         312 non-null    float32\n",
      " 2   2         312 non-null    float32\n",
      " 3   3         312 non-null    float32\n",
      " 4   4         312 non-null    float32\n",
      " 5   5         312 non-null    float32\n",
      " 6   6         312 non-null    float32\n",
      " 7   7         312 non-null    float32\n",
      " 8   8         312 non-null    float32\n",
      " 9   9         312 non-null    float32\n",
      " 10  10        312 non-null    float32\n",
      " 11  11        312 non-null    float32\n",
      " 12  12        312 non-null    float32\n",
      " 13  13        312 non-null    float32\n",
      " 14  14        312 non-null    float32\n",
      " 15  15        312 non-null    float32\n",
      " 16  16        312 non-null    float32\n",
      " 17  17        312 non-null    float32\n",
      " 18  18        312 non-null    float32\n",
      " 19  19        312 non-null    float32\n",
      " 20  20        312 non-null    float32\n",
      " 21  event     312 non-null    float32\n",
      " 22  duration  312 non-null    float64\n",
      "dtypes: float32(22), float64(1)\n",
      "memory usage: 29.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_2.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from utils.covariate_data_processing import pbc2_proccess_covariate_firstsolution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "______\n",
      "21\n",
      "______\n",
      "0\n",
      "______\n",
      "21\n",
      "______\n",
      "0\n",
      "______\n",
      "[ 0.11225496  2.06987187  3.72357902  6.68738364 14.30566203]\n",
      "______\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidlee/Documents/GitHub/Surtimesurvival/SurvTRACE/survtrace/utils.py:78: UserWarning: Got event/censoring at start time. Should be removed! It is set s.t. it has no contribution to loss.\n",
      "  warnings.warn(\"\"\"Got event/censoring at start time. Should be removed! It is set s.t. it has no contribution to loss.\"\"\")\n"
     ]
    }
   ],
   "source": [
    "y, df, df_train, df_y_train, df_test, df_y_test, df_val, df_y_val = pbc2_proccess_covariate_firstsolution(df_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "from SurvTRACE.survtrace.utils import set_random_seed\n",
    "from SurvTRACE.survtrace.model import SurvTraceSingle\n",
    "from SurvTRACE.survtrace.config import STConfig\n",
    "from SurvTRACE.survtrace.train_utils import Trainer\n",
    "\n",
    "set_random_seed(STConfig['seed'])\n",
    "\n",
    "hparams = {\n",
    "    'batch_size': 16,\n",
    "    'weight_decay': 1e-4,\n",
    "    'learning_rate': 1e-3,\n",
    "    'epochs': 20,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not found! will use cpu for training!\n",
      "[Train-0]: 19.586162328720093\n",
      "[Val-0]: 1.7043098211288452\n",
      "[Train-1]: 14.600073754787445\n",
      "[Val-1]: 1.3601312637329102\n",
      "[Train-2]: 11.605335652828217\n",
      "[Val-2]: 4.016164779663086\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-3]: 9.549132376909256\n",
      "[Val-3]: 6.628468036651611\n",
      "EarlyStopping counter: 2 out of 5\n",
      "[Train-4]: 7.639098823070526\n",
      "[Val-4]: 2.69443416595459\n",
      "EarlyStopping counter: 3 out of 5\n",
      "[Train-5]: 6.343803375959396\n",
      "[Val-5]: 3.8903112411499023\n",
      "EarlyStopping counter: 4 out of 5\n",
      "[Train-6]: 5.711188033223152\n",
      "[Val-6]: 1.3377878665924072\n",
      "[Train-7]: 5.798458844423294\n",
      "[Val-7]: 1.3409076929092407\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-8]: 5.771785795688629\n",
      "[Val-8]: 0.9428675770759583\n",
      "[Train-9]: 5.466524764895439\n",
      "[Val-9]: 1.1508796215057373\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-10]: 6.2678598165512085\n",
      "[Val-10]: 0.9152215123176575\n",
      "[Train-11]: 6.1375510692596436\n",
      "[Val-11]: 1.0840933322906494\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-12]: 5.865513503551483\n",
      "[Val-12]: 0.9480755925178528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "[Train-13]: 4.944110386073589\n",
      "[Val-13]: 1.0459644794464111\n",
      "EarlyStopping counter: 3 out of 5\n",
      "[Train-14]: 4.832498610019684\n",
      "[Val-14]: 0.9644650816917419\n",
      "EarlyStopping counter: 4 out of 5\n",
      "[Train-15]: 4.935785010457039\n",
      "[Val-15]: 1.0095516443252563\n",
      "EarlyStopping counter: 5 out of 5\n",
      "early stops at epoch 16\n"
     ]
    }
   ],
   "source": [
    "# get model\n",
    "model = SurvTraceSingle(STConfig)\n",
    "\n",
    "# initialize a trainer\n",
    "trainer = Trainer(model)\n",
    "train_loss, val_loss = trainer.fit(train_set=(df_train, df_y_train), val_set=(df_val, df_y_val),\n",
    "                                   batch_size=hparams['batch_size'],\n",
    "                                   epochs=hparams['epochs'],\n",
    "                                   learning_rate=hparams['learning_rate'],\n",
    "                                   weight_decay=hparams['weight_decay'],)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "start evaluation\n",
      "******************************\n",
      "For 0.25 quantile,\n",
      "TD Concordance Index - IPCW: 0.8509053798567893\n",
      "Brier Score: 0.09439263448872241\n",
      "For 0.5 quantile,\n",
      "TD Concordance Index - IPCW: 0.8409736625580714\n",
      "Brier Score: 0.1728135597120399\n",
      "For 0.75 quantile,\n",
      "TD Concordance Index - IPCW: 0.8578411350363606\n",
      "Brier Score: 0.2666990377386701\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "from SurvTRACE.survtrace.evaluate_utils import Evaluator\n",
    "evaluator = Evaluator(df, df_train.index)\n",
    "evaluator.eval(model, (df_test, df_y_test))\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='val')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('epoch',fontsize=20)\n",
    "plt.ylabel('loss', fontsize=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}